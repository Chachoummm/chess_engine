{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chachoummm/chess_engine/blob/main/Train_Evaluate_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uGqNaxG3_oVS"
      },
      "outputs": [],
      "source": [
        "#libraries\n",
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l3h2Ek_LNKG5"
      },
      "outputs": [],
      "source": [
        "rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ61olFSCwZB",
        "outputId": "7f234f18-e452-4c48-ebe7-a791742ec0d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "81hSxUdb4Jdr"
      },
      "outputs": [],
      "source": [
        "# comme c'est trop lourd c'est pas sur github donc le modèle a été entrainé en local et puis on y a fait appel sur colab à partir de Github\n",
        "data= pd.read_csv('/content/gdrive/MyDrive/filtered_2100_ranking (2).csv', index_col=None, header=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXzSKLpztIVE",
        "outputId": "8c0da9fb-f8d0-48ca-f46e-acb8e8a93e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(610240, 193)\n",
            "          a1    b1    c1    d1    e1  ... to_e8 to_f8 to_g8 to_h8 good_move\n",
            "601168  None  None  None  None  None  ...   0.0   0.0   0.0   0.0     False\n",
            "563510  None  None  None  None     R  ...   0.0   0.0   0.0   0.0     False\n",
            "62442   None  None  None     R  None  ...   0.0   0.0   0.0   0.0     False\n",
            "574307     R  None     B     Q     K  ...   0.0   0.0   0.0   0.0     False\n",
            "274284  None  None     K     R  None  ...   0.0   0.0   0.0   0.0     False\n",
            "\n",
            "[5 rows x 193 columns]\n"
          ]
        }
      ],
      "source": [
        "data = shuffle(data)\n",
        "print(data.shape)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#features transformations \n",
        "features = list(data.iloc[:, 0:192].columns)\n",
        "X = data[features]\n",
        "y = data['good_move']\n",
        "categorical_columns = list(X.iloc[:, 0:63].columns)\n",
        "numerical_columns = list(X.iloc[:, 64:192].columns)\n",
        "feature_columns = []\n",
        "\n",
        "for feature_name in categorical_columns:\n",
        "  vocabulary = X[feature_name].unique()\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in numerical_columns:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name,dtype = tf.float32))"
      ],
      "metadata": {
        "id": "W8T3wTTk7keC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train set (0.8) and test set (0.2)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set= train_test_split(data, test_size=0.2, random_state=0, shuffle=True)\n",
        "X_train,y_train, X_test,y_test = train_test_split(X,y, test_size=0.2, random_state=0, shuffle=True)\n",
        "\n",
        "# Verify the plits\n",
        "#print(train_set.shape, test_set.shape)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdD1rLPE7Oou",
        "outputId": "db73556a-a48a-4edc-c0e9-2ac6b0b313c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(488192, 192) (122048, 192) (488192,) (122048,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING PART"
      ],
      "metadata": {
        "id": "vFO949Tp6jMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E6MTlSW8tIis"
      },
      "outputs": [],
      "source": [
        "# Split train_set into batches :  \n",
        "  \n",
        "def split_into_batches(df, batch_size=100000):\n",
        "  nb_rows = len(df.index)\n",
        "  intervals = []\n",
        "  \n",
        "  for i in range(0, nb_rows + 1, batch_size):\n",
        "    intervals.append(i)\n",
        "  \n",
        "  if(intervals[-1] != nb_rows):\n",
        "    intervals.append(nb_rows)\n",
        "  \n",
        "  train_batches_X = []\n",
        "  train_batches_y = []\n",
        "  \n",
        "  for i in range(0, len(intervals) - 1):\n",
        "    train_batches_X.append(train_set.iloc[intervals[i]:intervals[i + 1], :][features])\n",
        "    train_batches_y.append(train_set.iloc[intervals[i]:intervals[i + 1], :]['good_move'])\n",
        "\n",
        "  return train_batches_X, train_batches_y\n",
        "\n",
        "train_batches_X, train_batches_y = split_into_batches(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YciGiX4o1PV2"
      },
      "outputs": [],
      "source": [
        "print(train_batches_X)\n",
        "print(train_batches_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "L9ipy3iV4Jwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07c5238-2a5a-4e46-8525-c2603a37bb65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/gdrive/MyDrive/Saved_good_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ]
        }
      ],
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns = feature_columns, model_dir='/content/gdrive/MyDrive/Saved_good_model',\n",
        "    warm_start_from=None, loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
        "    sparse_combiner='sum'\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jEllUHCz4J0B"
      },
      "outputs": [],
      "source": [
        "# Create the input function \n",
        "  \n",
        "def make_input_fn(data_df, label_df, num_epochs = 10, shuffle = True, batch_size = 32):\n",
        "  def input_function():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    return ds\n",
        "  return input_function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "K9GHrGm1Aeml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90edd79f-6c43-4e6b-cff8-476206d3a95d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "# Create a list with all the train input function : \n",
        "train_input_functions = []\n",
        "for df_X, df_y in zip(train_batches_X, train_batches_y):\n",
        "  train_input_functions.append(make_input_fn(df_X, df_y))\n",
        "\n",
        "print(len(train_input_functions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F--aBvspAeuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b2330f-1479-4bd3-fd92-e3cae89d80b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<======================================== NEW BATCH ========================================>\n",
            "Batch: 1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:401: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:1478: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  getter=tf.compat.v1.get_variable)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/ftrl.py:149: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/gdrive/MyDrive/Saved_good_model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.6931472, step = 0\n",
            "INFO:tensorflow:global_step/sec: 23.7943\n",
            "INFO:tensorflow:loss = 0.13955602, step = 100 (4.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 84.0184\n",
            "INFO:tensorflow:loss = 0.032262765, step = 200 (1.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.9294\n",
            "INFO:tensorflow:loss = 0.35488048, step = 300 (1.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.7876\n",
            "INFO:tensorflow:loss = 0.031557284, step = 400 (1.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.3863\n",
            "INFO:tensorflow:loss = 0.021540752, step = 500 (1.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 82.3438\n",
            "INFO:tensorflow:loss = 0.1414072, step = 600 (1.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.1234\n",
            "INFO:tensorflow:loss = 0.05326379, step = 700 (1.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.3898\n",
            "INFO:tensorflow:loss = 0.036918543, step = 800 (1.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.7942\n",
            "INFO:tensorflow:loss = 0.036202714, step = 900 (1.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.2548\n",
            "INFO:tensorflow:loss = 0.49396223, step = 1000 (1.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.9683\n",
            "INFO:tensorflow:loss = 0.28050008, step = 1100 (1.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.2863\n",
            "INFO:tensorflow:loss = 0.23395361, step = 1200 (1.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.4548\n",
            "INFO:tensorflow:loss = 0.04388219, step = 1300 (1.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.1544\n",
            "INFO:tensorflow:loss = 0.03323555, step = 1400 (1.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.9204\n",
            "INFO:tensorflow:loss = 0.2909923, step = 1500 (1.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.5087\n",
            "INFO:tensorflow:loss = 0.13793248, step = 1600 (1.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.6903\n",
            "INFO:tensorflow:loss = 0.027463611, step = 1700 (1.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 82.251\n",
            "INFO:tensorflow:loss = 0.02478595, step = 1800 (1.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.3108\n",
            "INFO:tensorflow:loss = 0.049383983, step = 1900 (1.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.49\n",
            "INFO:tensorflow:loss = 0.14572315, step = 2000 (1.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.5065\n",
            "INFO:tensorflow:loss = 0.1360682, step = 2100 (1.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.9954\n",
            "INFO:tensorflow:loss = 0.23122776, step = 2200 (1.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.8468\n",
            "INFO:tensorflow:loss = 0.11868381, step = 2300 (1.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.3548\n",
            "INFO:tensorflow:loss = 0.13752154, step = 2400 (1.330 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.9233\n",
            "INFO:tensorflow:loss = 0.14067742, step = 2500 (1.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.9939\n",
            "INFO:tensorflow:loss = 0.02092227, step = 2600 (1.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.1937\n",
            "INFO:tensorflow:loss = 0.021960802, step = 2700 (1.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.5527\n",
            "INFO:tensorflow:loss = 0.035448436, step = 2800 (1.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.6636\n",
            "INFO:tensorflow:loss = 0.240784, step = 2900 (1.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.2947\n",
            "INFO:tensorflow:loss = 0.3917734, step = 3000 (1.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.3579\n",
            "INFO:tensorflow:loss = 0.024357863, step = 3100 (1.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.2777\n",
            "INFO:tensorflow:loss = 0.26818597, step = 3200 (1.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 84.011\n",
            "INFO:tensorflow:loss = 0.12503038, step = 3300 (1.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 84.2385\n",
            "INFO:tensorflow:loss = 0.0328967, step = 3400 (1.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.3417\n",
            "INFO:tensorflow:loss = 0.2506247, step = 3500 (1.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.4826\n",
            "INFO:tensorflow:loss = 0.027317662, step = 3600 (1.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.5413\n",
            "INFO:tensorflow:loss = 0.15819009, step = 3700 (1.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 83.1679\n",
            "INFO:tensorflow:loss = 0.13429037, step = 3800 (1.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.9864\n",
            "INFO:tensorflow:loss = 0.05054806, step = 3900 (1.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.4312\n",
            "INFO:tensorflow:loss = 0.16954806, step = 4000 (1.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.6441\n",
            "INFO:tensorflow:loss = 0.14875242, step = 4100 (1.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.7893\n",
            "INFO:tensorflow:loss = 0.1340279, step = 4200 (1.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.8203\n",
            "INFO:tensorflow:loss = 0.039318644, step = 4300 (1.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.8883\n",
            "INFO:tensorflow:loss = 0.28093058, step = 4400 (1.337 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.2164\n",
            "INFO:tensorflow:loss = 0.030665312, step = 4500 (1.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.7023\n",
            "INFO:tensorflow:loss = 0.04391469, step = 4600 (1.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.361\n",
            "INFO:tensorflow:loss = 0.033442613, step = 4700 (1.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.909\n",
            "INFO:tensorflow:loss = 0.031162057, step = 4800 (1.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.2516\n",
            "INFO:tensorflow:loss = 0.105801046, step = 4900 (1.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.624\n",
            "INFO:tensorflow:loss = 0.13575625, step = 5000 (1.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.9311\n",
            "INFO:tensorflow:loss = 0.026605157, step = 5100 (1.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.4657\n",
            "INFO:tensorflow:loss = 0.23043236, step = 5200 (1.380 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.9606\n",
            "INFO:tensorflow:loss = 0.1571626, step = 5300 (1.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.6134\n",
            "INFO:tensorflow:loss = 0.2408602, step = 5400 (1.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.5309\n",
            "INFO:tensorflow:loss = 0.24439482, step = 5500 (1.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.1091\n",
            "INFO:tensorflow:loss = 0.033160437, step = 5600 (1.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.8233\n",
            "INFO:tensorflow:loss = 0.26030797, step = 5700 (1.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.5321\n",
            "INFO:tensorflow:loss = 0.22427031, step = 5800 (1.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.6123\n",
            "INFO:tensorflow:loss = 0.024730682, step = 5900 (1.457 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.296\n",
            "INFO:tensorflow:loss = 0.01977269, step = 6000 (1.386 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.3647\n",
            "INFO:tensorflow:loss = 0.13644762, step = 6100 (1.483 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.9543\n",
            "INFO:tensorflow:loss = 0.123903766, step = 6200 (1.452 sec)\n",
            "INFO:tensorflow:global_step/sec: 68.6654\n",
            "INFO:tensorflow:loss = 0.03379202, step = 6300 (1.455 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.2945\n",
            "INFO:tensorflow:loss = 0.05052285, step = 6400 (1.362 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.4072\n",
            "INFO:tensorflow:loss = 0.11452308, step = 6500 (1.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.9605\n",
            "INFO:tensorflow:loss = 0.022652823, step = 6600 (1.432 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.0259\n",
            "INFO:tensorflow:loss = 0.1322471, step = 6700 (1.446 sec)\n",
            "INFO:tensorflow:global_step/sec: 70.0592\n",
            "INFO:tensorflow:loss = 0.0196742, step = 6800 (1.431 sec)\n",
            "INFO:tensorflow:global_step/sec: 69.8863\n",
            "INFO:tensorflow:loss = 0.118435964, step = 6900 (1.432 sec)\n",
            "INFO:tensorflow:global_step/sec: 67.5522\n",
            "INFO:tensorflow:loss = 0.034291677, step = 7000 (1.476 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.9459\n",
            "INFO:tensorflow:loss = 0.06276649, step = 7100 (1.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.335\n",
            "INFO:tensorflow:loss = 0.13190734, step = 7200 (1.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.3778\n",
            "INFO:tensorflow:loss = 0.12836471, step = 7300 (1.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.6855\n",
            "INFO:tensorflow:loss = 0.0383361, step = 7400 (1.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.1788\n",
            "INFO:tensorflow:loss = 0.32383606, step = 7500 (1.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.5991\n",
            "INFO:tensorflow:loss = 0.12733564, step = 7600 (1.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.9543\n",
            "INFO:tensorflow:loss = 0.16606604, step = 7700 (1.314 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.614\n",
            "INFO:tensorflow:loss = 0.20300676, step = 7800 (1.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.3849\n",
            "INFO:tensorflow:loss = 0.13728641, step = 7900 (1.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.5884\n",
            "INFO:tensorflow:loss = 0.10123436, step = 8000 (1.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.5557\n",
            "INFO:tensorflow:loss = 0.020902261, step = 8100 (1.359 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.3362\n",
            "INFO:tensorflow:loss = 0.21906295, step = 8200 (1.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.1758\n",
            "INFO:tensorflow:loss = 0.028964283, step = 8300 (1.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.3683\n",
            "INFO:tensorflow:loss = 0.24179766, step = 8400 (1.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.8817\n",
            "INFO:tensorflow:loss = 0.21498354, step = 8500 (1.354 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.6022\n",
            "INFO:tensorflow:loss = 0.025608499, step = 8600 (1.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.279\n",
            "INFO:tensorflow:loss = 0.13043693, step = 8700 (1.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.4779\n",
            "INFO:tensorflow:loss = 0.021105573, step = 8800 (1.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.803\n",
            "INFO:tensorflow:loss = 0.23571926, step = 8900 (1.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.9907\n",
            "INFO:tensorflow:loss = 0.2543722, step = 9000 (1.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.4247\n",
            "INFO:tensorflow:loss = 0.22841801, step = 9100 (1.330 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.1202\n",
            "INFO:tensorflow:loss = 0.15264998, step = 9200 (1.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.0919\n",
            "INFO:tensorflow:loss = 0.028530434, step = 9300 (1.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.7782\n",
            "INFO:tensorflow:loss = 0.1547839, step = 9400 (1.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.3865\n",
            "INFO:tensorflow:loss = 0.16076033, step = 9500 (1.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.7112\n",
            "INFO:tensorflow:loss = 0.13115847, step = 9600 (1.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.1269\n",
            "INFO:tensorflow:loss = 0.11675801, step = 9700 (1.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.619\n",
            "INFO:tensorflow:loss = 0.094288975, step = 9800 (1.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 83.6552\n",
            "INFO:tensorflow:loss = 0.022320896, step = 9900 (1.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 75.5012\n",
            "INFO:tensorflow:loss = 0.15956211, step = 10000 (1.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.8016\n",
            "INFO:tensorflow:loss = 0.16525927, step = 10100 (1.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.0864\n",
            "INFO:tensorflow:loss = 0.26016954, step = 10200 (1.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.2109\n",
            "INFO:tensorflow:loss = 0.02975868, step = 10300 (1.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.0392\n",
            "INFO:tensorflow:loss = 0.026176635, step = 10400 (1.317 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.5123\n",
            "INFO:tensorflow:loss = 0.13437578, step = 10500 (1.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.3288\n",
            "INFO:tensorflow:loss = 0.113678575, step = 10600 (1.314 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.9867\n",
            "INFO:tensorflow:loss = 0.25975397, step = 10700 (1.331 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.8883\n",
            "INFO:tensorflow:loss = 0.13101527, step = 10800 (1.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.0776\n",
            "INFO:tensorflow:loss = 0.13982442, step = 10900 (1.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.3163\n",
            "INFO:tensorflow:loss = 0.22773053, step = 11000 (1.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.9668\n",
            "INFO:tensorflow:loss = 0.03939324, step = 11100 (1.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.0455\n",
            "INFO:tensorflow:loss = 0.22651438, step = 11200 (1.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.1974\n",
            "INFO:tensorflow:loss = 0.042180028, step = 11300 (1.348 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.0721\n",
            "INFO:tensorflow:loss = 0.27854973, step = 11400 (1.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.4123\n",
            "INFO:tensorflow:loss = 0.033292435, step = 11500 (1.344 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.8934\n",
            "INFO:tensorflow:loss = 0.159419, step = 11600 (1.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.2578\n",
            "INFO:tensorflow:loss = 0.2445738, step = 11700 (1.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.423\n",
            "INFO:tensorflow:loss = 0.113442436, step = 11800 (1.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.7792\n",
            "INFO:tensorflow:loss = 0.032417357, step = 11900 (1.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.5168\n",
            "INFO:tensorflow:loss = 0.15354697, step = 12000 (1.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.9087\n",
            "INFO:tensorflow:loss = 0.14722821, step = 12100 (1.333 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.4959\n",
            "INFO:tensorflow:loss = 0.03018193, step = 12200 (1.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.4532\n",
            "INFO:tensorflow:loss = 0.028579881, step = 12300 (1.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.6064\n",
            "INFO:tensorflow:loss = 0.12057592, step = 12400 (1.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.4636\n",
            "INFO:tensorflow:loss = 0.039743602, step = 12500 (1.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 82.9266\n",
            "INFO:tensorflow:loss = 0.23942974, step = 12600 (1.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.0495\n",
            "INFO:tensorflow:loss = 0.04134853, step = 12700 (1.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 85.1768\n",
            "INFO:tensorflow:loss = 0.12831642, step = 12800 (1.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.06\n",
            "INFO:tensorflow:loss = 0.12379377, step = 12900 (1.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 82.9091\n",
            "INFO:tensorflow:loss = 0.09450648, step = 13000 (1.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.3955\n",
            "INFO:tensorflow:loss = 0.03592002, step = 13100 (1.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.2032\n",
            "INFO:tensorflow:loss = 0.44905514, step = 13200 (1.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.21\n",
            "INFO:tensorflow:loss = 0.20757754, step = 13300 (1.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 84.7054\n",
            "INFO:tensorflow:loss = 0.09469485, step = 13400 (1.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.2024\n",
            "INFO:tensorflow:loss = 0.027946196, step = 13500 (1.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.4146\n",
            "INFO:tensorflow:loss = 0.21740414, step = 13600 (1.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.2231\n",
            "INFO:tensorflow:loss = 0.12832797, step = 13700 (1.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.6402\n",
            "INFO:tensorflow:loss = 0.23084424, step = 13800 (1.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.03\n",
            "INFO:tensorflow:loss = 0.13026127, step = 13900 (1.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 81.0276\n",
            "INFO:tensorflow:loss = 0.19287787, step = 14000 (1.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 82.4754\n",
            "INFO:tensorflow:loss = 0.13507977, step = 14100 (1.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.7634\n",
            "INFO:tensorflow:loss = 0.032858, step = 14200 (1.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.5629\n",
            "INFO:tensorflow:loss = 0.33532402, step = 14300 (1.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.6455\n",
            "INFO:tensorflow:loss = 0.14380702, step = 14400 (1.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.7104\n",
            "INFO:tensorflow:loss = 0.1887554, step = 14500 (1.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 79.0322\n",
            "INFO:tensorflow:loss = 0.13078293, step = 14600 (1.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.6658\n",
            "INFO:tensorflow:loss = 0.12503184, step = 14700 (1.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.0527\n",
            "INFO:tensorflow:loss = 0.21559283, step = 14800 (1.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.8764\n",
            "INFO:tensorflow:loss = 0.031900644, step = 14900 (1.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 71.3278\n",
            "INFO:tensorflow:loss = 0.029668033, step = 15000 (1.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.5865\n",
            "INFO:tensorflow:loss = 0.10654934, step = 15100 (1.362 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.7702\n",
            "INFO:tensorflow:loss = 0.16105889, step = 15200 (1.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.9516\n",
            "INFO:tensorflow:loss = 0.036608636, step = 15300 (1.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.42\n",
            "INFO:tensorflow:loss = 0.024672981, step = 15400 (1.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.4189\n",
            "INFO:tensorflow:loss = 0.047988854, step = 15500 (1.344 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.6099\n",
            "INFO:tensorflow:loss = 0.3159648, step = 15600 (1.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.5574\n",
            "INFO:tensorflow:loss = 0.17607835, step = 15700 (1.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.6565\n",
            "INFO:tensorflow:loss = 0.029332582, step = 15800 (1.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.2847\n",
            "INFO:tensorflow:loss = 0.0414915, step = 15900 (1.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 78.6495\n",
            "INFO:tensorflow:loss = 0.029953491, step = 16000 (1.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 80.1988\n",
            "INFO:tensorflow:loss = 0.38203317, step = 16100 (1.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 74.0257\n",
            "INFO:tensorflow:loss = 0.025054317, step = 16200 (1.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 76.9453\n",
            "INFO:tensorflow:loss = 0.34849733, step = 16300 (1.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 77.3818\n",
            "INFO:tensorflow:loss = 0.20423149, step = 16400 (1.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 72.4689\n",
            "INFO:tensorflow:loss = 0.14967307, step = 16500 (1.380 sec)\n",
            "INFO:tensorflow:global_step/sec: 73.309\n"
          ]
        }
      ],
      "source": [
        "# train the model on all the input functions\n",
        "i = 1\n",
        "for input_function in train_input_functions:\n",
        "  print('<======================================== NEW BATCH ========================================>')\n",
        "  print('Batch: ' + str(i))\n",
        "  i = i + 1\n",
        "  linear_est.train(input_function)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION PART"
      ],
      "metadata": {
        "id": "d_F9nGEs1GSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the test_set into batches :  \n",
        "  \n",
        "def split_into_batches(df, batch_size=50000):\n",
        "  nb_rows = len(df.index)\n",
        "  intervals = []\n",
        "  \n",
        "  for i in range(0, nb_rows + 1, batch_size):\n",
        "    intervals.append(i)\n",
        "  \n",
        "  if(intervals[-1] != nb_rows):\n",
        "    intervals.append(nb_rows)\n",
        "  \n",
        "  test_batches_X = []\n",
        "  test_batches_y = []\n",
        "  \n",
        "  for i in range(0, len(intervals) - 1):\n",
        "    test_batches_X.append(test_set.iloc[intervals[i]:intervals[i + 1], :][features])\n",
        "    test_batches_y.append(test_set.iloc[intervals[i]:intervals[i + 1], :]['good_move'])\n",
        "\n",
        "  return test_batches_X, test_batches_y\n",
        "\n",
        "test_batches_X, test_batches_y = split_into_batches(test_set)"
      ],
      "metadata": {
        "id": "_b-fte1Q1Gky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list with all the test input functions \n",
        "test_input_functions = []\n",
        "for df_X, df_y in zip(test_batches_X, test_batches_y):\n",
        "  test_input_functions.append(make_input_fn(df_X, df_y)\n",
        "\n",
        "print(len(test_input_functions))"
      ],
      "metadata": {
        "id": "DQzW1zjx1M9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on all the inpunt functions (Give score for the test i guess)\n",
        "i = 1\n",
        "for input_function in test_input_functions:\n",
        "  print('<======================================== NEW BATCH ========================================>')\n",
        "  print('Batch: ' + str(i))\n",
        "  i = i + 1\n",
        "  model_eval =linear_est.evaluate(input_function)\n"
      ],
      "metadata": {
        "id": "K_4Q1YwwmcSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_score = model_eval[\"loss\"]\n",
        "print(\"Loss: {0:f}\".format(loss_score))"
      ],
      "metadata": {
        "id": "Xxbn4CVjmqVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the summary statistic to get an idea of how big the error is.\n",
        "training_set['medv'].describe()"
      ],
      "metadata": {
        "id": "SsrxpptZmt0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICTION PART "
      ],
      "metadata": {
        "id": "UQqEGzE4AXoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list with all the pred input functions \n",
        "pred_input_functions = []\n",
        "for df_X in test_batches_X :\n",
        "  pred_input_functions.append(make_pred_input_fn(df_X))\n",
        "\n",
        "print(len(pred_input_functions))"
      ],
      "metadata": {
        "id": "INHbk6GTDi_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prediction input function\n",
        "\n",
        "def make_pred_input_fn(data_df, num_epochs = 10, shuffle = True, batch_size = 32):\n",
        "  def input_function():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    return ds\n",
        "  return input_function        "
      ],
      "metadata": {
        "id": "8SMCZzOJA2zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model prediction on all the inpunt functions \n",
        "i = 1\n",
        "for input_function in pred_input_functions:\n",
        "  print('<======================================== NEW BATCH ========================================>')\n",
        "  print('Batch: ' + str(i))\n",
        "  i = i + 1\n",
        "  y_predict = estimator.predict( pred_input_fn)"
      ],
      "metadata": {
        "id": "fVnD6hEomt52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = list(p[\"predictions\"] for p in itertools.islice(y, 6))"
      ],
      "metadata": {
        "id": "XhcI-AmGvLSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predictions: {}\".format(str(predictions)))"
      ],
      "metadata": {
        "id": "07KdiHEgvLn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "  tf.feature_column.make_parse_example_spec(feature_columns))\n",
        "\n",
        "estimator_base_path = '/content/gdrive/MyDrive/Saved_train_model'\n",
        "estimator_path = linear_est.export_saved_model(estimator_base_path, serving_input_fn)"
      ],
      "metadata": {
        "id": "BIHdmyPOf-xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST4CKkdEPe7I",
        "outputId": "c946b035-bc49-48f5-988d-44b230dab983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-12-08 14:30:40.445803: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Upload started and will continue reading any new data as it's added to the logdir.\n",
            "\n",
            "To stop uploading, press Ctrl-C.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/OUMaqezDRxeeKIY6KGOGdg/\n",
            "\n",
            "\u001b[1m[2021-12-08T14:30:40]\u001b[0m Started scanning logdir.\n",
            "\n",
            "\n",
            "Interrupted.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
            "    sys.exit(run_main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/main.py\", line 46, in run_main\n",
            "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/program.py\", line 276, in main\n",
            "    return runner(self.flags) or 0\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 657, in run\n",
            "    return _run(flags, self._experiment_url_callback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 125, in _run\n",
            "    intent.execute(server_info, channel)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 473, in execute\n",
            "    sys.stdout.write(end_message + \"\\n\")\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!tensorboard --logdir='\\content\\gdrive\\MyDrive\\Model_train_Ourdata' \\\n",
        "  --name \"Projet DATAB\" \\\n",
        "  --description \"Training results from https://colab.sandbox.google.com/github/tensorflow/tensorboard/blob/master/docs/tbdev_getting_started.ipynb\" \\\n",
        "  #--one_shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPaN6RjpPe_l"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvf0RFkXAezi"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVA3TdibAe2g"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeLkv5jkWoew"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "history = model.fit()\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Evaluate_Code.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}